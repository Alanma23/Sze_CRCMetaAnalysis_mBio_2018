#!bash

# Load needed R
module load R/3.3.0

#Define respective directory short cuts
DOWNDIR=data/raw/dejea
WORKDIR=data/process/dejea
REF=data/references

rm -f $DOWNDIR/*.sra

# Had to use the user specific Qiime default since qvalue of 35 resulted in too many
# lost sequences and eliminated too much of the data set.

# Need to add a preamble about the data set and what it encompasses.
# Also need to add author information and other such stuff.
# e.g. type of sequencer used and other such data

# Downloading only a specific set of files from the sra
wget -r -q -np -nd -k -P $DOWNDIR ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP045/SRP045685/

# Convert to fasta files that will be used
for sample in $DOWNDIR/*.sra
do
	fastq-dump $sample -O $WORKDIR
	fastq=${sample//sra/fastq}
	fastq=${fastq//raw/process}

	mothur "#fastq.info(fastq=$fastq);
		trim.seqs(fasta=current, qfile=current, maxambig=0, maxhomop=8, qwindowaverage=25, qwindowsize=50)"
	rm *.logfile
done

# Combined the seperate fasta files  to one file
cat $WORKDIR/*trim.fasta > $WORKDIR/combined.fasta

# Create a group file
grep '^>' $WORKDIR/combined.fasta | cut -c 2- > $WORKDIR/header.txt
sed 's/\..*//g' $WORKDIR/header.txt > $WORKDIR/group.txt
paste --delimiters='\t' $WORKDIR/header.txt $WORKDIR/group.txt > $WORKDIR/combined.groups

# Remove unessary files
rm -f $WORKDIR/*.fastq $WORKDIR/*.scrap.* $WORKDIR/*.trim.* $WORKDIR/SRR*fasta $WORKDIR/SRR*qual $WORKDIR/header.txt $WORKDIR/group.txt

# Run mothur on the combined file
mothur "#summary.seqs(fasta=$WORKDIR/combined.fasta, processors=8);
	unique.seqs(fasta=$WORKDIR/combined.fasta);
	count.seqs(name=current, group=$WORKDIR/combined.groups);
	summary.seqs(fasta=current, count=current);
	align.seqs(fasta=$WORKDIR/combined.unique.fasta, reference=$REF/silva.seed.align, flip=T, processors=8);
	summary.seqs(fasta=current, count=current);
	screen.seqs(fasta=$WORKDIR/combined.unique.align, count=$WORKDIR/combined.count_table, summary=$WORKDIR/combined.unique.summary, end=28425, optimize=start, criteria=95, minlength=200, maxhomop=8, processors=8);
	filter.seqs(fasta=$WORKDIR/combined.unique.good.align, vertical=T, trump=.);
	unique.seqs(fasta=current, count=current);
	summary.seqs(fasta=current, count=current);
	pre.cluster(fasta=current, count=current, diffs=2);
	chimera.uchime(fasta=current, count=current, dereplicate=t, processors=8);
	remove.seqs(fasta=current, accnos=current);
	summary.seqs(fasta=current, count=current);
	classify.seqs(fasta=current, count=current, reference=$REF/trainset14_032015.pds.fasta, taxonomy=$REF/trainset14_032015.pds.tax, cutoff=80, processors=8);
	remove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota);
	cluster.split(fasta=current, count=current, taxonomy=current, splitmethod=classify, taxlevel=4, cutoff=0.15);
	make.shared(list=current, count=current, label=0.03);
	classify.otu(list=current, count=current, taxonomy=current, label=0.03);
	get.oturep(fasta=current, count=current, list=current, label=0.03, method=abundance);
	count.groups()"

R -e "source('code/dejea.R')"

mothur "#sub.sample(shared=$WORKDIR/dejea.shared, size=401, label=0.03);
	dist.shared(shared=$WORKDIR/dejea.shared, calc=braycurtis, label=0.03, subsample=401, iters=100, processors=8);
	summary.single(shared=$WORKDIR/dejea.shared, calc=nseqs-sobs-shannon-shannoneven, subsample=T)"

mv $WORKDIR/*.cons.taxonomy $WORKDIR/dejea.taxonomy
mv $WORKDIR/*0.03.rep.fasta $WORKDIR/dejea.rep.seqs

rm $WORKDIR/combined.*
rm $WORKDIR/*rabund





