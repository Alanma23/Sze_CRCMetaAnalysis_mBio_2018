#!bash

#Load needed R
module load R/3.3.3
module load samtools/1.3.1
module load bedtools2/2.25.0
tempMothur=/nfs/turbo/schloss-lab/msze/axiom_home_stuff/bin/mothurV1.39.3/mothur/mothur
SEQDIR=data/raw/hale/Chia_files
DOWNDIR=data/raw/hale
WORKDIR=data/process/hale
REF=data/references

# (Hale, V et al 2017).  Sequences obtained directly from authors 
# Metadata was obtained directly from authors
# Need 150GB of RAM to run through and 3 processors (update as maximum MEM changes)
# ***EDIT*** need at least 900GB to run through the clustering

# Convert to fasta files that will be used
for sample in $SEQDIR/*.bam
do
	fastq1=${sample//.bam/_1.fastq}
	fastq2=${sample//.bam/_2.fastq}

	bamToFastq -i $sample -fq $fastq1 -fq2 $fastq2

	mv $SEQDIR/*.fastq $DOWNDIR/

done

# transfer fastq files to working directory
mv $DOWNDIR/*.fastq $WORKDIR/


# Make a files file for mothur using bash commands
#Get read 1 fastq
ls $WORKDIR/*_1.fastq > $WORKDIR/read1.txt
# Get read 2 fastq
ls $WORKDIR/*_2.fastq > $WORKDIR/read2.txt
# Get Names to be used
ls $WORKDIR/*_1.fastq | cut -c19-24 > $WORKDIR/names.txt
#Combine everything together
paste -d '\t' $WORKDIR/names.txt $WORKDIR/read1.txt $WORKDIR/read2.txt > $WORKDIR/hale.files


# Run mothur for sequencing processing on combined file
$tempMothur "#make.contigs(file=$WORKDIR/hale.files);
	summary.seqs(fasta=current, processors=4);
	unique.seqs(fasta=current);
	align.seqs(fasta=current, reference=$REF/silva.seed.align, flip=T);
	count.seqs(name=current, group=current);
	summary.seqs(fasta=current, count=current)"
$tempMothur	"#screen.seqs(fasta=$WORKDIR/hale.trim.contigs.unique.align, count=$WORKDIR/hale.trim.contigs.count_table, summary=$WORKDIR/hale.trim.contigs.unique.summary, start=6388, end=28464, maxlength=578, maxambig=0, maxhomop=8, processors=4);
	filter.seqs(fasta=current, vertical=T, trump=.);
	unique.seqs(fasta=current, count=current);
	summary.seqs(fasta=current, count=current)"
$tempMothur "#pre.cluster(fasta=$WORKDIR/hale.trim.contigs.unique.good.filter.unique.fasta, count=$WORKDIR/hale.trim.contigs.unique.good.filter.count_table, diffs=6);
	chimera.uchime(fasta=current, count=current, dereplicate=t);
	remove.seqs(fasta=current, accnos=current);
	classify.seqs(fasta=current, count=current, reference=$REF/trainset14_032015.pds.fasta, taxonomy=$REF/trainset14_032015.pds.tax, cutoff=80);
	remove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota)"
$tempMothur "#cluster.split(fasta=$WORKDIR/hale.trim.contigs.unique.good.filter.unique.precluster.pick.pick.fasta, count=$WORKDIR/hale.trim.contigs.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.count_table, taxonomy=$WORKDIR/hale.trim.contigs.unique.good.filter.unique.precluster.pick.pds.wang.pick.taxonomy, method=opti, metric=mcc, taxlevel=5, cluster=f, cutoff=0.03, processors=25)"
$tempMothur "#cluster.split(file=$WORKDIR/hale.trim.contigs.unique.good.filter.unique.precluster.pick.pick.file, method=opti, metric=mcc)"
$tempMothur	"#make.shared(list=$WORKDIR/hale.trim.contigs.unique.good.filter.unique.precluster.pick.pick.opti_mcc.unique_list.list, count=$WORKDIR/hale.trim.contigs.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.count_table, label=0.03);
	classify.otu(list=current, count=current, taxonomy=$WORKDIR/hale.trim.contigs.unique.good.filter.unique.precluster.pick.pds.wang.pick.taxonomy, label=0.03);
	get.oturep(fasta=$WORKDIR/hale.trim.contigs.unique.good.filter.unique.precluster.pick.pick.fasta, count=current, list=current, label=0.03, method=abundance);
	count.groups()"

# Match metadata with the shared file
R -e "source('code/hale.R')"

$tempMothur "#sub.sample(shared=$WORKDIR/hale.shared, size=1017, label=0.03);
	dist.shared(shared=$WORKDIR/hale.shared, calc=braycurtis, label=0.03, subsample=1017, iters=100);
	summary.single(shared=$WORKDIR/hale.shared, calc=nseqs-sobs-shannon-shannoneven, subsample=1017)"


mv $WORKDIR/*.cons.taxonomy $WORKDIR/hale.taxonomy
mv $WORKDIR/*0.03.rep.fasta $WORKDIR/hale.rep.seqs

rm $WORKDIR/*rabund
rm $WORKDIR/*.fastq
rm $WORKDIR/*.filter
rm $WORKDIR/*.contigs.*
rm $WORKDIR/names.txt $WORKDIR/read2.txt $WORKDIR/read1.txt

gzip $WORKDIR/hale.taxonomy $WORKDIR/hale.rep.seqs $WORKDIR/hale.shared
gzip $WORKDIR/hale.0.03.subsample.shared
