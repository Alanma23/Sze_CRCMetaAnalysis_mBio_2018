#!bash

#Load needed R
module load R/3.3.0
mothurRv=/mnt/EXT/Schloss-data/bin/mothur
DOWNDIR=data/raw/Zeller
WORKDIR=data/process/zeller
REF=data/references

# Need to add in a bunch of stuff on the study and what they were looking for.
# Might adjust parameters to those set by authors of original manuscript
# (Geng, J et al 2013).  mothur default for 454 allowed only an average of
# 855 sequence per sample. Author method leave ~1,190 sequences per sample. 
# The SRA project ID is SRP016877.

# Download the data set
while IFS= read -r FILE
do
	#Removes any potential endings from text read in
	target=${FILE//[$'\t\r\n']}
	wget -r -np -nd -k -P $DOWNDIR ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByStudy/sra/ERP/ERP005/ERP005534/$target
	
done <$DOWNDIR/ZellerToKeep.txt

# Convert to fasta files that will be used
for FILE in $(ls $DOWNDIR/*.sra)
do
	fastq-dump --split-files $FILE -O $WORKDIR
	rm $FILE
done

# Make a files file for mothur using bash commands
#Get read 1 fastq
ls $WORKDIR/*_1.fastq > $WORKDIR/read1.txt
# Get read 2 fastq
ls $WORKDIR/*_2.fastq > $WORKDIR/read2.txt
# Get Names to be used
ls $WORKDIR/*_1.fastq | cut -c21-29 > $WORKDIR/names.txt
#Combine everything together
paste -d '\t' $WORKDIR/names.txt $WORKDIR/read1.txt $WORKDIR/read2.txt > $WORKDIR/zeller.files

# Run mothur for sequencing processing on combined file
$mothurRv "#make.contigs(file=$WORKDIR/zeller.files);
	summary.seqs(fasta=current, processors=4);
	screen.seqs(fasta=current, group=current, summary=current, maxambig=0, maxlength=275);
	summary.seqs(fasta=current, group=current);
	unique.seqs(fasta=current);
	count.seqs(name=current, group=current);
	summary.seqs(fasta=current, count=current);
	align.seqs(fasta=current, reference=$REF/silva.seed.align, flip=T);
	summary.seqs(fasta=current, count=current);
	screen.seqs(fasta=current, count=current, summary=current, start=13862, end=23444, maxhomop=8);
	summary.seqs(fasta=current, count=current);
	screen.seqs(fasta=$WORKDIR/combined.unique.align, count=$WORKDIR/combined.count_table, start=1046, optimize=end, criteria=95, minlength=200, maxhomop=8);
	filter.seqs(fasta=current, vertical=T, trump=.);
	unique.seqs(fasta=current, count=current);
	pre.cluster(fasta=current, count=current, diffs=2);
	chimera.vsearch(fasta=current, count=current, dereplicate=t);
	remove.seqs(fasta=current, accnos=current);
	classify.seqs(fasta=current, count=current, reference=$REF/trainset14_032015.pds.fasta, taxonomy=$REF/trainset14_032015.pds.tax, cutoff=80);
	remove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota);
	cluster.split(fasta=current, count=current, taxonomy=current, method=opti, metric=mcc, taxlevel=5, cutoff=0.03);
	make.shared(list=current, count=current, label=0.03);
	count.groups(shared=current);
	classify.otu(list=current, count=current, taxonomy=current, label=0.03);
	get.oturep(fasta=current, count=current, list=current, label=0.03, method=abundance)"

# Match metadata with the shared file
#R -e "source('code/geng.R')"

#$mothurRv "#sub.sample(shared=$WORKDIR/geng.shared, label=0.03);
#	dist.shared(shared=$WORKDIR/geng.shared, calc=braycurtis, label=0.03, subsample=T, iters=100, processors=8);
#	summary.single(shared=$WORKDIR/geng.shared, calc=nseqs-sobs-shannon-shannoneven, subsample=T)"

#mv $WORKDIR/*.cons.taxonomy $WORKDIR/geng.taxonomy
#mv $WORKDIR/*0.03.rep.fasta $WORKDIR/geng.rep.seqs

#rm $WORKDIR/combined.*
#rm $WORKDIR/*rabund





