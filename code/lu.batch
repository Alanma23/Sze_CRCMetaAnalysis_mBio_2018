#!bash

#Load needed R
module load R/3.3.3
tempMothur=/nfs/turbo/pschloss/msze/axiom_home_stuff/bin/mothurV1.39.3/mothur/mothur
DOWNDIR=data/raw/Lu
WORKDIR=data/process/lu
REF=data/references

# Need to add in a bunch of stuff on the study and what they were looking for.
# Might adjust parameters to those set by authors of original manuscript
# (Lu, Y et al 2016).  The SRA project ID is SRP064975. 
# Need 80GB of RAM to run through

# Download the data set
wget -r -q -np -nd -k -P $DOWNDIR ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP064/SRP064975/

# Convert to fasta files that will be used
for sample in $DOWNDIR/*.sra
do
	fastq-dump --split-files $sample -O $WORKDIR

done

# Make a files file from the fastq files in the directory
ls $WORKDIR/*_1.fastq > $WORKDIR/read1.txt
ls $WORKDIR/*_2.fastq > $WORKDIR/read2.txt
ls $WORKDIR/*_1.fastq | cut -c17-26 > $WORKDIR/names.txt
paste -d '\t' $WORKDIR/names.txt $WORKDIR/read1.txt $WORKDIR/read2.txt > $WORKDIR/lu.files

# Remove unnecessary files pt1
rm $WORKDIR/names.txt $WORKDIR/read1.txt $WORKDIR/read2.txt


# Run mothur for sequencing processing on combined file
$tempMothur "#make.contigs(file=$WORKDIR/lu.files, processors=6);
	summary.seqs(fasta=current);
	unique.seqs(fasta=current);
	align.seqs(fasta=current, reference=$REF/silva.seed.align, flip=T);
	count.seqs(name=current, group=current);
	summary.seqs(fasta=current, count=current)"

#	screen.seqs(fasta=$WORKDIR/lu.trim.contigs.good.unique.align, count=$WORKDIR/lu.trim.contigs.good.count_table, start=6322, optimize=end, criteria=95, minlength=200, maxhomop=8);
#	filter.seqs(fasta=current, vertical=T, trump=.);
#	unique.seqs(fasta=current, count=current);
#	summary.seqs(fasta=current, count=current);
#	pre.cluster(fasta=current, count=current, diffs=2);
#	chimera.uchime(fasta=current, count=current, dereplicate=t);
#	remove.seqs(fasta=current, accnos=current);
#	classify.seqs(fasta=current, count=current, reference=$REF/trainset14_032015.pds.fasta, taxonomy=$REF/trainset14_032015.pds.tax, cutoff=80);
#	remove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota);
#	cluster.split(fasta=$WORKDIR/lu.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.fasta, count=$WORKDIR/lu.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.count_table, taxonomy=$WORKDIR/lu.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.taxonomy, splitmethod=classify, taxlevel=5, cutoff=0.15);
#	make.shared(list=current, count=current, label=0.03);
#	classify.otu(list=current, count=current, taxonomy=current, label=0.03);
#	get.oturep(fasta=current, count=current, list=current, label=0.03, method=abundance)"

# Match metadata with the shared file
#R -e "source('code/lu.R')"

#mothur "#sub.sample(shared=$WORKDIR/lu.matched.shared, label=0.03);
#	dist.shared(shared=$WORKDIR/lu.matched.shared, calc=braycurtis, label=0.03, subsample=T, iters=100, processors=8);
#	summary.single(shared=$WORKDIR/lu.matched.shared, calc=nseqs-sobs-shannon-shannoneven, subsample=T)"

#mothur "#sub.sample(shared=$WORKDIR/lu.unmatched.shared, label=0.03);
#	dist.shared(shared=$WORKDIR/lu.unmatched.shared, calc=braycurtis, label=0.03, subsample=T, iters=100, processors=8);
#	summary.single(shared=$WORKDIR/lu.unmatched.shared, calc=nseqs-sobs-shannon-shannoneven, subsample=T)"

#mv $WORKDIR/*.cons.taxonomy $WORKDIR/lu.taxonomy
#mv $WORKDIR/*0.03.rep.fasta $WORKDIR/lu.rep.seqs

#rm $WORKDIR/*.contigs.*
#rm $WORKDIR/*rabund
#rm $WORKDIR/*.fastq
#rm $WORKDIR/*.filter

